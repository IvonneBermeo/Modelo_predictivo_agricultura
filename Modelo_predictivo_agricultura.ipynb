{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "318f4121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      N   P   K        ph  crop\n",
      "0   90  42  43  6.502985  rice\n",
      "1   85  58  41  7.038096  rice\n",
      "2   60  55  44  7.840207  rice\n",
      "3   74  35  40  6.980401  rice\n",
      "4   78  42  42  7.628473  rice\n",
      "5   69  37  42  7.073454  rice\n",
      "6   69  55  38  5.700806  rice\n",
      "7   94  53  40  5.718627  rice\n",
      "8   89  54  38  6.685346  rice\n",
      "9   68  58  38  6.336254  rice\n",
      "10  91  53  40  5.386168  rice\n",
      "11  90  46  42  7.502834  rice\n",
      "12  78  58  44  5.108682  rice\n",
      "13  93  56  36  6.984354  rice\n",
      "14  94  50  37  6.948020  rice\n",
      "\n",
      "                  N            P            K           ph\n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000\n",
      "mean     50.551818    53.362727    48.149091     6.469480\n",
      "std      36.917334    32.985883    50.647931     0.773938\n",
      "min       0.000000     5.000000     5.000000     3.504752\n",
      "25%      21.000000    28.000000    20.000000     5.971693\n",
      "50%      37.000000    51.000000    32.000000     6.425045\n",
      "75%      84.250000    68.000000    49.000000     6.923643\n",
      "max     140.000000   145.000000   205.000000     9.935091\n",
      "\n",
      " N       0\n",
      "P       0\n",
      "K       0\n",
      "ph      0\n",
      "crop    0\n",
      "dtype: int64\n",
      "\n",
      " ['rice' 'maize' 'chickpea' 'kidneybeans' 'pigeonpeas' 'mothbeans'\n",
      " 'mungbean' 'blackgram' 'lentil' 'pomegranate' 'banana' 'mango' 'grapes'\n",
      " 'watermelon' 'muskmelon' 'apple' 'orange' 'papaya' 'coconut' 'cotton'\n",
      " 'jute' 'coffee']\n",
      "\n",
      "\n",
      "F1-score for N: 0.10689900116508289\n",
      "F1-score for P: 0.08426955444720076\n",
      "F1-score for K: 0.13831456375684123\n",
      "F1-score for ph: 0.045464856528065166\n",
      "\n",
      " Mejor característica predictiva: {'K': 0.13831456375684123}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el dataset\n",
    "crops = pd.read_csv(\"soil_measures.csv\")\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(\"\\n\", crops.head(15))\n",
    "print(\"\\n\", crops.describe())\n",
    "\n",
    "# Comprobar valores faltantes\n",
    "print(\"\\n\", crops.isna().sum())\n",
    "\n",
    "# Compruebe cuántos cultivos tenemos, es decir, objetivo de clases múltiples\n",
    "print(\"\\n\", crops.crop.unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Dividir en conjuntos de características y objetivos\n",
    "X = crops.drop(columns=\"crop\")\n",
    "y = crops[\"crop\"]\n",
    "\n",
    "# Divida los datos en conjuntos de entrenamiento y prueba.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Cree un diccionario para almacenar el rendimiento del modelo para cada característica.\n",
    "feature_performance = {}\n",
    "\n",
    "# Entrene un modelo de regresión logística para cada característica\n",
    "for feature in [\"N\", \"P\", \"K\", \"ph\"]:\n",
    "    log_reg = LogisticRegression(multi_class=\"multinomial\", max_iter=200, solver='lbfgs')\n",
    "    log_reg.fit(X_train_scaled[:, [X.columns.get_loc(feature)]], y_train)\n",
    "    y_pred = log_reg.predict(X_test_scaled[:, [X.columns.get_loc(feature)]])\n",
    "    \n",
    "    # Calcule la puntuación F1, la media armónica de precisión y recuperación\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    # Agregue pares de puntuación característica-f1 al diccionario\n",
    "    feature_performance[feature] = f1\n",
    "    print(f\"F1-score for {feature}: {f1}\")\n",
    "\n",
    "# K obtuvo la mejor puntuación en F1\n",
    "# Almacenar en el diccionario best_predictive_feature\n",
    "best_predictive_feature = {\"K\": feature_performance[\"K\"]}\n",
    "print(\"\\n Mejor característica predictiva:\", best_predictive_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74a4e4",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "La característica N (nitrógeno) tiene una puntuación F1 de aproximadamente 0.107. Esto indica que, cuando se usa solo N para predecir el tipo de cultivo, el modelo tiene un rendimiento bajo.\n",
    "\n",
    "La característica P (fósforo) tiene una puntuación F1 de aproximadamente 0.084, lo que también indica un rendimiento bajo.\n",
    "\n",
    "La característica K (potasio) tiene la puntuación F1 más alta entre las evaluadas, con aproximadamente 0.138. Aunque es la mejor característica predictiva entre las cuatro, sigue siendo relativamente baja en términos absolutos.\n",
    "\n",
    "La característica ph tiene la puntuación F1 más baja, con aproximadamente 0.045. Esto indica que es la menos efectiva de las cuatro características para predecir el tipo de cultivo.\n",
    "\n",
    "Entre las características evaluadas, K (potasio) es la mejor en términos de su capacidad predictiva, pero su puntuación F1 sigue siendo baja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489700a",
   "metadata": {},
   "source": [
    "### Modelo combinando caracteristicas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45443ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with all features: 0.6475209891596989\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"multinomial\", max_iter=200, solver='lbfgs')\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "f1 = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"F1-score with all features: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6034ff0",
   "metadata": {},
   "source": [
    "Obtener una puntuación F1 de aproximadamente 0.648 utilizando todas las características combinadas es un resultado significativamente mejor comparado con las puntuaciones individuales de las características. Esto indica que el modelo de regresión logística puede capturar mejor la relación entre las características y la variable objetivo cuando tiene acceso a todas las características en lugar de solo una."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42f8b1",
   "metadata": {},
   "source": [
    "La puntuación F1 de 0.648 sugiere que el modelo está haciendo un trabajo razonable en la clasificación de los tipos de cultivos. No es perfecta, pero es una mejora considerable respecto a usar características individuales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854ed60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
